-- start_ignore
-- wait a while as sometimes the gpmmon is not ready
\c gpperfmon
CREATE OR REPLACE FUNCTION wait_for_gpmmon_work() RETURNS void AS $$
DECLARE
DECLARE
start_time timestamptz := clock_timestamp();
updated bool;
BEGIN
	-- we don't want to wait forever; loop will exit after 60 seconds
	FOR i IN 1 .. 1000 LOOP
		SELECT(SELECT count(*) > 0 from queries_history ) INTO updated;
		EXIT WHEN updated;

		-- wait a little
		PERFORM pg_sleep_for('100 milliseconds');
	END LOOP;
	-- report time waited in postmaster log (where it won't change test output)
	RAISE log 'wait_for_gpmmon_work delayed % seconds',
	EXTRACT(epoch FROM clock_timestamp() - start_time);
END
$$ LANGUAGE plpgsql;
select wait_for_gpmmon_work();
 wait_for_gpmmon_work 
----------------------
 
(1 row)

\c contrib_regression
select sess_id from pg_stat_activity where pg_backend_pid()=pid;
 sess_id 
---------
  401542
(1 row)

\gset
CREATE TABLE foo(a int, b int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Cloudberry Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
CREATE TABLE test(a int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'a' as the Cloudberry Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
\timing
INSERT INTO foo SELECT i + 1 from generate_series(0,80000000) as i;
Time: 149935.380 ms (02:29.935)
\timing
-- end_ignore
-- test query text in multiple lines
INSERT INTO test
SELECT generate_series(0,10);
-- test nested query
create or replace function n_join_foo_test() returns integer as $$
begin
	return (select count(*) from foo join test on foo.a=test.a);
end;
$$ language plpgsql;
select * from n_join_foo_test();
 n_join_foo_test 
-----------------
              10
(1 row)

DROP TABLE foo;
DROP TABLE test;
\c gpperfmon
-- start_ignore
select pg_sleep(100);
 pg_sleep 
----------
 
(1 row)

analyze system_history;
analyze database_history;
analyze diskspace_history;
analyze queries_history;
-- end_ignore
select count(*) > 0 from system_now;
 ?column? 
----------
 t
(1 row)

select count(*) > 0 from database_now;
 ?column? 
----------
 t
(1 row)

select count(*) > 0 from diskspace_now;
 ?column? 
----------
 t
(1 row)

select count(*) > 0 from system_history;
 ?column? 
----------
 t
(1 row)

select count(*) > 0 from database_history;
 ?column? 
----------
 t
(1 row)

select count(*) > 0 from diskspace_history;
 ?column? 
----------
 t
(1 row)

select ccnt, status, query_text, length(query_plan) > 0 from queries_history
where ssid = :sess_id order by ccnt;
 ccnt | status |                             query_text                              | ?column? 
------+--------+---------------------------------------------------------------------+----------
    2 | done   | select sess_id from pg_stat_activity where pg_backend_pid()=pid;    | t
    4 | done   | select sess_id from pg_stat_activity where pg_backend_pid()=pid;    | t
    8 | done   | INSERT INTO foo SELECT i + 1 from generate_series(0,80000000) as i; | t
   10 | done   | INSERT INTO test                                                   +| t
      |        | SELECT generate_series(0,10);                                       | 
   13 | done   | select * from n_join_foo_test();                                    | t
(5 rows)

SELECT COUNT(*) FROM (SELECT DISTINCT ccnt FROM queries_history
where ssid = :sess_id) as temp;
 count 
-------
     5
(1 row)

select mem_peak>0, cpu_currpct>0, spill_file_size>0, skew_cpu>0, status, query_text, length(query_plan) > 0 from queries_history
where ssid = :sess_id and query_text = 'INSERT INTO foo SELECT i + 1 from generate_series(0,80000000) as i;'
 ?column? | ?column? | ?column? | ?column? | status |                             query_text                              | ?column? 
----------+----------+----------+----------+--------+---------------------------------------------------------------------+----------
 t        | t        | t        | t        | done   | INSERT INTO foo SELECT i + 1 from generate_series(0,80000000) as i; | t
(1 row)

